{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thinkful - 4.4.2 - Challenge - NLP Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(ALICE, ’S, ADVENTURES, IN, WONDERLAND, Lewis,...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(THE, MILLENNIUM, FULCRUM, EDITION, 3.0, Alice...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0        1\n",
       "0  (ALICE, ’S, ADVENTURES, IN, WONDERLAND, Lewis,...  Carroll\n",
       "1  (THE, MILLENNIUM, FULCRUM, EDITION, 3.0, Alice...  Carroll\n",
       "2  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "3  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "4                                      (Oh, dear, !)  Carroll"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "#persuasion = gutenberg.raw('Data/austen-persuasion.txt')\n",
    "#alice = gutenberg.raw('Data/carroll-alice.txt')\n",
    "filename1 = 'Data/austen-persuasion.txt'\n",
    "file1 = open(filename1,'rt')\n",
    "persuasion = file1.read()\n",
    "file1.close()\n",
    "\n",
    "filename2 = 'Data/carroll-alice.txt'\n",
    "file2 = open(filename2,'rt')\n",
    "alice = file2.read()\n",
    "file2.close()\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)\n",
    "\n",
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)\n",
    "\n",
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parts of Speech Bags Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADV', 'PROPN', 'ADJ', 'ADP', 'X', 'DET', 'NUM', 'PUNCT', 'CCONJ', 'PRON', 'PART', 'NOUN', 'INTJ', 'VERB']\n"
     ]
    }
   ],
   "source": [
    "# Utility function to create a list of the potential parts of speech\n",
    "def parts_of_speech(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    parts_speech = [token.pos_ for token in text]\n",
    "    \n",
    "    # Return all words.\n",
    "    #return [item[0] for item in Counter(parts_speech)]\n",
    "    return parts_speech\n",
    "\n",
    "# Set up the bags.\n",
    "alicepos = parts_of_speech(alice_doc)\n",
    "persuasionpos = parts_of_speech(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "pos_words = list(set(alicepos + persuasionpos))\n",
    "\n",
    "print(pos_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parts of Speech Counter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADV</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>X</th>\n",
       "      <th>DET</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PRON</th>\n",
       "      <th>PART</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>VERB</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ALICE, ’S, ADVENTURES, IN, WONDERLAND, Lewis,...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>(THE, MILLENNIUM, FULCRUM, EDITION, 3.0, Alice...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ADV PROPN ADJ ADP  X DET NUM PUNCT CCONJ PRON PART NOUN INTJ VERB  \\\n",
       "0   0     5   0   1  0   0   0     0     0    0    1    0    0    0   \n",
       "1   3     6   3   8  0   6   1     6     6    3    2   11    0   13   \n",
       "2   7     2   7   8  0   6   0     7     2    4    1    8    0   11   \n",
       "3   6     2   1   4  0   3   0     3     1    2    1    2    0    5   \n",
       "4   0     0   0   0  0   0   0     1     0    0    0    0    2    0   \n",
       "\n",
       "                                       text_sentence text_source  length  \n",
       "0  (ALICE, ’S, ADVENTURES, IN, WONDERLAND, Lewis,...     Carroll       1  \n",
       "1  (THE, MILLENNIUM, FULCRUM, EDITION, 3.0, Alice...     Carroll       1  \n",
       "2  (So, she, was, considering, in, her, own, mind...     Carroll       1  \n",
       "3  (There, was, nothing, so, VERY, remarkable, in...     Carroll       1  \n",
       "4                                      (Oh, dear, !)     Carroll       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a data frame with features for each part of speech corresponding to each word in our part of speech word set.\n",
    "# Each value is the count of the times the part of speech appears in each sentence.\n",
    "def pos_features(sentences, pos_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df1 = pd.DataFrame(columns=pos_words)\n",
    "    df1['text_sentence'] = sentences[0]\n",
    "    df1['text_source'] = sentences[1]\n",
    "    df1.loc[:, pos_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df1['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        pos = [token.pos_ for token in sentence]\n",
    "        df1['length'] = len(sentence)\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for pos1 in pos:\n",
    "            df1.loc[i, pos1] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "    \n",
    "    return df1\n",
    "        \n",
    "# Create our data frame with features. This can take a while to run.\n",
    "pos_counts = pos_features(sentences, pos_words)\n",
    "pos_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Common Words Bags Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Counter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 2000\n",
      "Processing row 2500\n",
      "Processing row 3000\n",
      "Processing row 3500\n",
      "Processing row 4000\n",
      "Processing row 4500\n",
      "Processing row 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>directly</th>\n",
       "      <th>morcar</th>\n",
       "      <th>drown</th>\n",
       "      <th>new</th>\n",
       "      <th>warm</th>\n",
       "      <th>heartily</th>\n",
       "      <th>ascertain</th>\n",
       "      <th>similar</th>\n",
       "      <th>clean</th>\n",
       "      <th>farm</th>\n",
       "      <th>...</th>\n",
       "      <th>setting</th>\n",
       "      <th>destroy</th>\n",
       "      <th>absurd</th>\n",
       "      <th>recollect</th>\n",
       "      <th>cousin</th>\n",
       "      <th>stoop</th>\n",
       "      <th>minute</th>\n",
       "      <th>inconvenient</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ALICE, ’S, ADVENTURES, IN, WONDERLAND, Lewis,...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(THE, MILLENNIUM, FULCRUM, EDITION, 3.0, Alice...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  directly morcar drown new warm heartily ascertain similar clean farm  \\\n",
       "0        0      0     0   0    0        0         0       0     0    0   \n",
       "1        0      0     0   0    0        0         0       0     0    0   \n",
       "2        0      0     0   0    0        0         0       0     0    0   \n",
       "3        0      0     0   0    0        0         0       0     0    0   \n",
       "4        0      0     0   0    0        0         0       0     0    0   \n",
       "\n",
       "      ...     setting destroy absurd recollect cousin stoop minute  \\\n",
       "0     ...           0       0      0         0      0     0      0   \n",
       "1     ...           0       0      0         0      0     0      0   \n",
       "2     ...           0       0      0         0      0     0      0   \n",
       "3     ...           0       0      0         0      0     0      0   \n",
       "4     ...           0       0      0         0      0     0      0   \n",
       "\n",
       "  inconvenient                                      text_sentence text_source  \n",
       "0            0  (ALICE, ’S, ADVENTURES, IN, WONDERLAND, Lewis,...     Carroll  \n",
       "1            0  (THE, MILLENNIUM, FULCRUM, EDITION, 3.0, Alice...     Carroll  \n",
       "2            0  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "3            0  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "4            0                                      (Oh, dear, !)     Carroll  \n",
       "\n",
       "[5 rows x 3262 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df2 = pd.DataFrame(columns=common_words)\n",
    "    df2['text_sentence'] = sentences[0]\n",
    "    df2['text_source'] = sentences[1]\n",
    "    df2.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df2['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words)]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df2.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 500 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "            \n",
    "    return df2\n",
    "\n",
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADV</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>X</th>\n",
       "      <th>DET</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PRON</th>\n",
       "      <th>...</th>\n",
       "      <th>setting</th>\n",
       "      <th>destroy</th>\n",
       "      <th>absurd</th>\n",
       "      <th>recollect</th>\n",
       "      <th>cousin</th>\n",
       "      <th>stoop</th>\n",
       "      <th>minute</th>\n",
       "      <th>inconvenient</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ALICE, ’S, ADVENTURES, IN, WONDERLAND, Lewis,...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(THE, MILLENNIUM, FULCRUM, EDITION, 3.0, Alice...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ADV PROPN ADJ ADP  X DET NUM PUNCT CCONJ PRON     ...     setting destroy  \\\n",
       "0   0     5   0   1  0   0   0     0     0    0     ...           0       0   \n",
       "1   3     6   3   8  0   6   1     6     6    3     ...           0       0   \n",
       "2   7     2   7   8  0   6   0     7     2    4     ...           0       0   \n",
       "3   6     2   1   4  0   3   0     3     1    2     ...           0       0   \n",
       "4   0     0   0   0  0   0   0     1     0    0     ...           0       0   \n",
       "\n",
       "  absurd recollect  cousin stoop minute inconvenient  \\\n",
       "0      0         0       0     0      0            0   \n",
       "1      0         0       0     0      0            0   \n",
       "2      0         0       0     0      0            0   \n",
       "3      0         0       0     0      0            0   \n",
       "4      0         0       0     0      0            0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (ALICE, ’S, ADVENTURES, IN, WONDERLAND, Lewis,...     Carroll  \n",
       "1  (THE, MILLENNIUM, FULCRUM, EDITION, 3.0, Alice...     Carroll  \n",
       "2  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "3  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "4                                      (Oh, dear, !)     Carroll  \n",
       "\n",
       "[5 rows x 3277 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counts2 = pos_counts.drop(['text_sentence','text_source'], axis=1)\n",
    "df = pd.concat([pos_counts2, word_counts], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models: Original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words with Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.987094743469\n",
      "\n",
      "Test set score: 0.878716375649\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = word_counts.drop(['text_sentence','text_source'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.4,random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words with Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.988039030532\n",
      "\n",
      "Test set score: 0.882491741387\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = df['text_source']\n",
    "X = np.array(df.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.4,random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_train_1 = rfc.score(X_train, y_train)\n",
    "rfc_test_1 = rfc.score(X_test, y_test)\n",
    "\n",
    "print('Training set score:', rfc_train_1)\n",
    "print('\\nTest set score:', rfc_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words with Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3177, 3275) (3177,)\n",
      "Training set score: 0.946175637394\n",
      "\n",
      "Test set score: 0.893345917886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "lr_train_1 = lr.score(X_train, y_train)\n",
    "lr_test_1 = lr.score(X_test, y_test)\n",
    "\n",
    "print('Training set score:', lr_train_1)\n",
    "print('\\nTest set score:', lr_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words with Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.90462700661\n",
      "\n",
      "Test set score: 0.886267107126\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "clf_train_1 = clf.score(X_train, y_train)\n",
    "clf_test_1 = clf.score(X_test, y_test)\n",
    "\n",
    "print('Training set score:', clf_train_1)\n",
    "print('\\nTest set score:', clf_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words with Support Vector Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.98363235757\n",
      "\n",
      "Test set score: 0.907031618688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_train_1 = svm.score(X_train, y_train)\n",
    "svm_test_1 = svm.score(X_test, y_test)\n",
    "\n",
    "print('Training set score:', svm_train_1)\n",
    "print('\\nTest set score:', svm_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 0:\n",
    "\n",
    "Recall that the logistic regression model's best performance on the test set was 93%. \n",
    "* See what you can do to improve performance. Suggested avenues of investigation include: Other modeling techniques (SVM?), making more features that take advantage of the spaCy information (include grammar, phrases, POS, etc), making sentence-level features (number of words, amount of punctuation), or including contextual information (length of previous and next sentences, words repeated from one sentence to the next, etc), and anything else your heart desires. \n",
    "* Make sure to design your models on the test set, or use cross_validation with multiple folds, and see if you can get accuracy above 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words and Parts of Speech with Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.98929807995\n",
      "\n",
      "Test set score: 0.875412930628\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = df['text_source']\n",
    "X = np.array(df.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.4,random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "rfc_train_2 = rfc.score(X_train, y_train)\n",
    "rfc_test_2 = rfc.score(X_test, y_test)\n",
    "\n",
    "print('Training set score:', rfc_train_2)\n",
    "print('\\nTest set score:', rfc_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Bag of Words and Parts of Speech with Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3177, 3275) (3177,)\n",
      "Training set score: 0.946175637394\n",
      "\n",
      "Test set score: 0.893345917886\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "lr_train_2 = lr.score(X_train, y_train)\n",
    "lr_test_2 = lr.score(X_test, y_test)\n",
    "\n",
    "print('Training set score:', lr_train_2)\n",
    "print('\\nTest set score:', lr_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words and Parts of Speech with Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.90462700661\n",
      "\n",
      "Test set score: 0.885323265691\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "clf_train_2 = clf.score(X_train, y_train)\n",
    "clf_test_2 = clf.score(X_test, y_test)\n",
    "\n",
    "print('Training set score:', clf_train_2)\n",
    "print('\\nTest set score:', clf_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words and Parts of Speech with Support Vector Machines**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.98363235757\n",
      "\n",
      "Test set score: 0.907031618688\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "svm_train_2 = svm.score(X_train, y_train)\n",
    "svm_test_2 = svm.score(X_test, y_test)\n",
    "\n",
    "print('Training set score:', svm_train_2)\n",
    "print('\\nTest set score:', svm_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>BoW</th>\n",
       "      <th>BoW with PoS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting Regression</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model    BoW BoW with PoS\n",
       "0      Random Forest Classifier  0.882        0.875\n",
       "1           Logistic Regression  0.893        0.893\n",
       "2  Gradient Boosting Regression  0.886        0.885\n",
       "3       Support Vector Machines  0.907        0.907"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = np.array([['Random Forest Classifier',\"%0.3f\" % rfc_test_1,\n",
    "                      \"%0.3f\" % rfc_test_2],\n",
    "                  ['Logistic Regression',\"%0.3f\" % lr_test_1,\n",
    "                      \"%0.3f\" % lr_test_2],\n",
    "                  ['Gradient Boosting Regression',\"%0.3f\" % clf_test_1,\n",
    "                      \"%0.3f\" % clf_test_2],\n",
    "                  ['Support Vector Machines',\"%0.3f\" % svm_test_1,\n",
    "                      \"%0.3f\" % svm_test_2]])\n",
    "\n",
    "df_summary = pd.DataFrame(summary)\n",
    "df_summary.columns = ['Model','BoW','BoW with PoS']\n",
    "\n",
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 1:\n",
    "\n",
    "* Find out whether your new model is good at identifying Alice in Wonderland vs any other work, Persuasion vs any other work, or Austen vs any other work. This will involve pulling a new book from the Project Gutenberg corpus (print(gutenberg.fileids()) for a list) and processing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMMA By Jane Austen Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy di\n"
     ]
    }
   ],
   "source": [
    "# Clean the Emma data.\n",
    "filename3 = 'Data/austen-emma.txt'\n",
    "file3 = open(filename3,'rt')\n",
    "emma = file3.read()\n",
    "file3.close()\n",
    "\n",
    "emma = re.sub(r'VOLUME \\w+', '', emma)\n",
    "emma = re.sub(r'CHAPTER \\w+', '', emma)\n",
    "emma = text_cleaner(emma)\n",
    "print(emma[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice # of sentences:  1645\n",
      "Emma # of sentences:  12265\n"
     ]
    }
   ],
   "source": [
    "# Parse our cleaned data.\n",
    "emma_doc = nlp(emma)\n",
    "\n",
    "# Group into sentences.\n",
    "emma_sents = [[sent, \"Emma\"] for sent in emma_doc.sents]\n",
    "\n",
    "print(\"Alice # of sentences: \",len(alice_sents))\n",
    "print(\"Emma # of sentences: \",len(emma_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n",
      "Processing row 0\n",
      "Processing row 500\n",
      "Processing row 1000\n",
      "Processing row 1500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADV</th>\n",
       "      <th>PROPN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>ADP</th>\n",
       "      <th>X</th>\n",
       "      <th>DET</th>\n",
       "      <th>NUM</th>\n",
       "      <th>PUNCT</th>\n",
       "      <th>CCONJ</th>\n",
       "      <th>PRON</th>\n",
       "      <th>...</th>\n",
       "      <th>setting</th>\n",
       "      <th>destroy</th>\n",
       "      <th>absurd</th>\n",
       "      <th>recollect</th>\n",
       "      <th>cousin</th>\n",
       "      <th>stoop</th>\n",
       "      <th>minute</th>\n",
       "      <th>inconvenient</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(EMMA, By, Jane, Austen, Emma, Woodhouse, ,, h...</td>\n",
       "      <td>Emma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(She, was, the, youngest, of, the, two, daught...</td>\n",
       "      <td>Emma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Her, mother, had, died, too, long, ago, for, ...</td>\n",
       "      <td>Emma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Sixteen, years, had, Miss, Taylor, been, in, ...</td>\n",
       "      <td>Emma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Between, _, them)</td>\n",
       "      <td>Emma</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3277 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ADV PROPN ADJ ADP  X DET NUM PUNCT CCONJ PRON     ...     setting destroy  \\\n",
       "0   2     5   7   6  0   4   2     8     4    1     ...           0       0   \n",
       "1   2     0   6   6  0   4   1     5     1    1     ...           0       0   \n",
       "2   3     0   8   7  0   3   0     3     1    1     ...           0       0   \n",
       "3   2     5   2   5  0   3   1     4     1    0     ...           0       0   \n",
       "4   0     0   0   1  0   0   0     0     0    1     ...           0       0   \n",
       "\n",
       "  absurd recollect  cousin stoop minute inconvenient  \\\n",
       "0      0         0       0     0      0            0   \n",
       "1      0         0       0     0      0            0   \n",
       "2      0         0       0     0      0            0   \n",
       "3      0         0       0     0      0            0   \n",
       "4      0         0       0     0      0            0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (EMMA, By, Jane, Austen, Emma, Woodhouse, ,, h...        Emma  \n",
       "1  (She, was, the, youngest, of, the, two, daught...        Emma  \n",
       "2  (Her, mother, had, died, too, long, ago, for, ...        Emma  \n",
       "3  (Sixteen, years, had, Miss, Taylor, been, in, ...        Emma  \n",
       "4                                 (Between, _, them)        Emma  \n",
       "\n",
       "[5 rows x 3277 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Emma is quite long, let's cut it down to the same length as Alice.\n",
    "emma_sents = emma_sents[0:len(alice_sents)]\n",
    "\n",
    "# Build a new Bag of Words data frame for Emma word counts.\n",
    "# We'll use the same common words from Alice and Persuasion.\n",
    "emma_sentences = pd.DataFrame(emma_sents)\n",
    "\n",
    "# Build a new Bag of Words data frame for Emma word counts.\n",
    "# We'll use the same common words from Alice and Persuasion.\n",
    "emma_bow = bow_features(emma_sentences, common_words)\n",
    "\n",
    "# Create our data frame with features. This can take a while to run.\n",
    "emma_pos_counts = pos_features(emma_sentences, pos_words)\n",
    "\n",
    "emma_pos_counts = emma_pos_counts.drop(['text_sentence','text_source'], axis=1)\n",
    "df1 = pd.concat([emma_pos_counts, emma_bow], axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine the Emma sentence data with the Alice data from the test set.\n",
    "X_Emma_test = np.concatenate((X_train[y_train[y_train=='Carroll'].index],\n",
    "    df1.drop(['text_sentence','text_source'], 1)), axis=0)\n",
    "y_Emma_test = pd.concat([y_train[y_train=='Carroll'],pd.Series(['Austen'] * df1.shape[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.682797731569\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1518</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>712</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen     1518      127\n",
       "Carroll     712      288"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
    "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machines Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.526654064272\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1067</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>674</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen     1067      578\n",
       "Carroll     674      326"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.\n",
    "print('\\nTest set score:', svm.score(X_Emma_test, y_Emma_test))\n",
    "svm_Emma_predicted = svm.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, svm_Emma_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting Classifier Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.522117202268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1141</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>760</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen     1141      504\n",
       "Carroll     760      240"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.\n",
    "print('\\nTest set score:', clf.score(X_Emma_test, y_Emma_test))\n",
    "clf_Emma_predicted = clf.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, clf_Emma_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
